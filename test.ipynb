{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/opt/homebrew/opt/apache-spark/libexec/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|jinko_avg|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark sessionの作成\n",
    "# spark.ui.enabled trueとするとSparkのGUI画面を確認することができます\n",
    "# spark.eventLog.enabled true　とすると　GUIで実行ログを確認することができます\n",
    "# GUIなどの確認は最後のセクションで説明を行います。\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chapter1\") \\\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\") \\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"JST\") \\\n",
    "    .config(\"spark.ui.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql(\"show tables\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.option(\"multiLine\",\"true\").option(\"encoding\",\"SJIS\").csv(\"/Users/isomasaki/pyspark_batch/dataset/jinko.csv\",header=True,sep=\",\",inferSchema=False)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "|都道府県コード|都道府県名|元号|和暦（年）|西暦（年）|注  |人口（総数）|人口（男）|人口（女）|\n",
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "|00            |全国      |大正|9         |1920      |null|55963053    |28044185  |27918868  |\n",
      "|01            |北海道    |大正|9         |1920      |null|2359183     |1244322   |1114861   |\n",
      "|02            |青森県    |大正|9         |1920      |null|756454      |381293    |375161    |\n",
      "|03            |岩手県    |大正|9         |1920      |null|845540      |421069    |424471    |\n",
      "|04            |宮城県    |大正|9         |1920      |null|961768      |485309    |476459    |\n",
      "|05            |秋田県    |大正|9         |1920      |null|898537      |453682    |444855    |\n",
      "|06            |山形県    |大正|9         |1920      |null|968925      |478328    |490597    |\n",
      "|07            |福島県    |大正|9         |1920      |null|1362750     |673525    |689225    |\n",
      "|08            |茨城県    |大正|9         |1920      |null|1350400     |662128    |688272    |\n",
      "|09            |栃木県    |大正|9         |1920      |null|1046479     |514255    |532224    |\n",
      "|10            |群馬県    |大正|9         |1920      |null|1052610     |514106    |538504    |\n",
      "|11            |埼玉県    |大正|9         |1920      |null|1319533     |641161    |678372    |\n",
      "|12            |千葉県    |大正|9         |1920      |null|1336155     |656968    |679187    |\n",
      "|13            |東京都    |大正|9         |1920      |null|3699428     |1952989   |1746439   |\n",
      "|14            |神奈川県  |大正|9         |1920      |null|1323390     |689751    |633639    |\n",
      "|15            |新潟県    |大正|9         |1920      |null|1776474     |871532    |904942    |\n",
      "|16            |富山県    |大正|9         |1920      |null|724276      |354775    |369501    |\n",
      "|17            |石川県    |大正|9         |1920      |null|747360      |364375    |382985    |\n",
      "|18            |福井県    |大正|9         |1920      |null|599155      |293181    |305974    |\n",
      "|19            |山梨県    |大正|9         |1920      |null|583453      |290817    |292636    |\n",
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "|          code|    kenmei|gengo|    wareki|   seireki| chu|       sokei|jinko_male|jinko_female|\n",
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "|都道府県コード|都道府県名| 元号|和暦（年）|西暦（年）|  注|人口（総数）|人口（男）|  人口（女）|\n",
      "|            00|      全国| 大正|         9|      1920|null|    55963053|  28044185|    27918868|\n",
      "|            01|    北海道| 大正|         9|      1920|null|     2359183|   1244322|     1114861|\n",
      "|            02|    青森県| 大正|         9|      1920|null|      756454|    381293|      375161|\n",
      "|            03|    岩手県| 大正|         9|      1920|null|      845540|    421069|      424471|\n",
      "|            04|    宮城県| 大正|         9|      1920|null|      961768|    485309|      476459|\n",
      "|            05|    秋田県| 大正|         9|      1920|null|      898537|    453682|      444855|\n",
      "|            06|    山形県| 大正|         9|      1920|null|      968925|    478328|      490597|\n",
      "|            07|    福島県| 大正|         9|      1920|null|     1362750|    673525|      689225|\n",
      "|            08|    茨城県| 大正|         9|      1920|null|     1350400|    662128|      688272|\n",
      "|            09|    栃木県| 大正|         9|      1920|null|     1046479|    514255|      532224|\n",
      "|            10|    群馬県| 大正|         9|      1920|null|     1052610|    514106|      538504|\n",
      "|            11|    埼玉県| 大正|         9|      1920|null|     1319533|    641161|      678372|\n",
      "|            12|    千葉県| 大正|         9|      1920|null|     1336155|    656968|      679187|\n",
      "|            13|    東京都| 大正|         9|      1920|null|     3699428|   1952989|     1746439|\n",
      "|            14|  神奈川県| 大正|         9|      1920|null|     1323390|    689751|      633639|\n",
      "|            15|    新潟県| 大正|         9|      1920|null|     1776474|    871532|      904942|\n",
      "|            16|    富山県| 大正|         9|      1920|null|      724276|    354775|      369501|\n",
      "|            17|    石川県| 大正|         9|      1920|null|      747360|    364375|      382985|\n",
      "|            18|    福井県| 大正|         9|      1920|null|      599155|    293181|      305974|\n",
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#日本語のカラム名をローマ字へ変換\n",
    "from pyspark.sql.types import StructType,StructField,StringType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "struct = StructType([\n",
    "    StructField(\"code\",StringType(),False),\n",
    "    StructField(\"kenmei\",StringType(),False),\n",
    "    StructField(\"gengo\",StringType(),False),\n",
    "    StructField(\"wareki\",StringType(),False),\n",
    "    StructField(\"seireki\",StringType(),False),\n",
    "    StructField(\"chu\",StringType(),False),\n",
    "    StructField(\"sokei\",StringType(),False),\n",
    "    StructField(\"jinko_male\",StringType(),False),\n",
    "    StructField(\"jinko_female\",StringType(),False)\n",
    "])\n",
    "\n",
    "df = spark.read.option(\"multiLine\",\"true\").option(\"encoding\",\"SJIS\") \\\n",
    ".csv(\"/Users/isomasaki/pyspark_batch/dataset/jinko.csv\",header=False,sep=\",\",inferSchema=False,schema=struct)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "|code|                kenmei|gengo|wareki|seireki| chu|    sokei|jinko_male|jinko_female|\n",
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "|  00|                  全国| 平成|     2|   1990|null|123611167|  60696724|    62914443|\n",
      "|  0A|          人口集中地区| 平成|     2|   1990|null| 78152452|  38564229|    39588223|\n",
      "|  0B|人口集中地区以外の地区| 平成|     2|   1990|null| 45458715|  22132495|    23326220|\n",
      "|  01|                北海道| 平成|     2|   1990|null|  5643647|   2722988|     2920659|\n",
      "|  02|                青森県| 平成|     2|   1990|null|  1482873|    704758|      778115|\n",
      "|  03|                岩手県| 平成|     2|   1990|null|  1416928|    680197|      736731|\n",
      "|  04|                宮城県| 平成|     2|   1990|null|  2248558|   1105103|     1143455|\n",
      "|  05|                秋田県| 平成|     2|   1990|null|  1227478|    584678|      642800|\n",
      "|  06|                山形県| 平成|     2|   1990|null|  1258390|    607041|      651349|\n",
      "|  07|                福島県| 平成|     2|   1990|null|  2104058|   1024354|     1079704|\n",
      "|  08|                茨城県| 平成|     2|   1990|null|  2845382|   1419117|     1426265|\n",
      "|  09|                栃木県| 平成|     2|   1990|null|  1935168|    962571|      972597|\n",
      "|  10|                群馬県| 平成|     2|   1990|null|  1966265|    971704|      994561|\n",
      "|  11|                埼玉県| 平成|     2|   1990|null|  6405319|   3245868|     3159451|\n",
      "|  12|                千葉県| 平成|     2|   1990|null|  5555429|   2802774|     2752655|\n",
      "|  13|                東京都| 平成|     2|   1990|null| 11855563|   5969773|     5885790|\n",
      "|  14|              神奈川県| 平成|     2|   1990|null|  7980391|   4098147|     3882244|\n",
      "|  15|                新潟県| 平成|     2|   1990|null|  2474583|   1200376|     1274207|\n",
      "|  16|                富山県| 平成|     2|   1990|null|  1120161|    538640|      581521|\n",
      "|  17|                石川県| 平成|     2|   1990|null|  1164628|    562684|      601944|\n",
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.gengo == \"平成\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+--------------------+\n",
      "|                kenmei|            male_avg|          female_avg|\n",
      "+----------------------+--------------------+--------------------+\n",
      "|人口集中地区以外の地区|2.0976203166666668E7|2.2272045166666668E7|\n",
      "|                佐賀県|            408192.5|            456442.5|\n",
      "|                栃木県|   987741.8333333334|            999415.5|\n",
      "|                京都府|  1268325.3333333333|  1360099.3333333333|\n",
      "|                香川県|   485871.8333333333|   523763.6666666667|\n",
      "|                愛媛県|   692188.3333333334|   774376.1666666666|\n",
      "|                秋田県|   542928.3333333334|            604578.5|\n",
      "|                広島県|           1387308.5|  1478006.8333333333|\n",
      "|                宮崎県|            542386.5|            608793.0|\n",
      "|              鹿児島県|            818506.0|            929134.0|\n",
      "|                埼玉県|  3492880.3333333335|  3443447.8333333335|\n",
      "|                三重県|            893167.5|   944959.6666666666|\n",
      "|                島根県|            356034.5|   388621.6666666667|\n",
      "|                徳島県|   383399.1666666667|            423152.0|\n",
      "|                岐阜県|  1009389.1666666666|  1073025.1666666667|\n",
      "|                新潟県|           1175463.5|  1249345.3333333333|\n",
      "|                山形県|            583603.5|   627811.6666666666|\n",
      "|              神奈川県|           4360756.0|           4252978.5|\n",
      "|                群馬県|   986385.1666666666|  1013610.6666666666|\n",
      "|                岩手県|   659592.6666666666|   714973.1666666666|\n",
      "+----------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "df.where(df.gengo == \"平成\").groupBy(\"kenmei\")\\\n",
    "    .agg(sf.avg(\"jinko_male\").alias(\"male_avg\"),sf.avg(\"jinko_female\").alias(\"female_avg\")).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_t = df.where(df.gengo == \"平成\").groupBy(\"kenmei\")\\\n",
    "    .agg(sf.avg(\"jinko_male\").alias(\"male_avg\"),sf.avg(\"jinko_female\").alias(\"jinko_female_avg\"))\\\n",
    "        .filter(df.kenmei != \"人口集中地区以外の地区\").sort(\"male_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------------+\n",
      "|  kenmei|         male_avg| jinko_female_avg|\n",
      "+--------+-----------------+-----------------+\n",
      "|  鳥取県|287885.3333333333|314291.3333333333|\n",
      "|  島根県|         356034.5|388621.6666666667|\n",
      "|  高知県|372268.1666666667|         418517.0|\n",
      "|  徳島県|383399.1666666667|         423152.0|\n",
      "|  福井県|         395512.5|420182.6666666667|\n",
      "|  佐賀県|         408192.5|         456442.5|\n",
      "|  山梨県|425777.8333333333|441831.1666666667|\n",
      "|  香川県|485871.8333333333|523763.6666666667|\n",
      "|和歌山県|         490624.0|547112.3333333334|\n",
      "|  富山県|         532857.0|573049.8333333334|\n",
      "|  宮崎県|         542386.5|         608793.0|\n",
      "|  秋田県|542928.3333333334|         604578.5|\n",
      "|  石川県|         566064.0|         604518.5|\n",
      "|  大分県|571530.6666666666|638773.6666666666|\n",
      "|  山形県|         583603.5|627811.6666666666|\n",
      "|  沖縄県|         654622.0|679050.6666666666|\n",
      "|  岩手県|659592.6666666666|714973.1666666666|\n",
      "|  滋賀県|         662391.0|         680326.0|\n",
      "|  奈良県|671178.6666666666|734736.6666666666|\n",
      "|  青森県|675238.6666666666|751182.1666666666|\n",
      "+--------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_after_t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#カラムナーフォーマットへの変換\n",
    "df_after_t.write.mode(\"overwrite\").parquet(\"/Users/isomasaki/pyspark_batch/dataset/parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isomasaki/.zshenv:4: command not found: goenv\n",
      "total 8\n",
      "-rw-r--r--  1 isomasaki  staff     0 Jul 21 09:19 _SUCCESS\n",
      "-rw-r--r--  1 isomasaki  staff  2083 Jul 21 09:19 part-00000-1f96165f-5412-4cc1-87e3-4200f6fe7bfb-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/isomasaki/pyspark_batch/dataset/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スモールファイル問題に対処するためにファイルをまとめる(ノードの数)\n",
    "df_after_t.repartition(1).write.mode(\"overwrite\").parquet(\"/Users/isomasaki/pyspark_batch/dataset/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isomasaki/.zshenv:4: command not found: goenv\n",
      "total 8\n",
      "-rw-r--r--  1 isomasaki  staff     0 Jul 21 09:19 _SUCCESS\n",
      "-rw-r--r--  1 isomasaki  staff  2083 Jul 21 09:19 part-00000-e4f5624d-8fa8-4c24-b8ae-1f49d59da26f-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/isomasaki/pyspark_batch/dataset/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_after_t.repartition(1).write.partitionBy(\"kenmei\").mode(\"overwrite\").parquet(\"/Users/isomasaki/pyspark_batch/dataset/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isomasaki/.zshenv:4: command not found: goenv\n",
      "total 0\n",
      "-rw-r--r--  1 isomasaki  staff    0 Jul 21 09:19 _SUCCESS\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=三重県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=京都府\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=人口集中地区\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=佐賀県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=全国\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=兵庫県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=北海道\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=千葉県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=和歌山県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=埼玉県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=大分県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=大阪府\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=奈良県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=宮城県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=宮崎県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=富山県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=山口県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=山形県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=山梨県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=岐阜県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=岡山県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=岩手県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=島根県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=広島県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=徳島県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=愛媛県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=愛知県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=新潟県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=東京都\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=栃木県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=沖縄県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=滋賀県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=熊本県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=石川県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=神奈川県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=福井県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=福岡県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=福島県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=秋田県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=群馬県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=茨城県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=長崎県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=長野県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=青森県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=静岡県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=香川県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=高知県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=鳥取県\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 isomasaki  staff  128 Jul 21 09:19 \u001b[34mkenmei=鹿児島県\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/isomasaki/pyspark_batch/dataset/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isomasaki/.zshenv:4: command not found: goenv\n",
      "total 8\n",
      "-rw-r--r--  1 isomasaki  staff  786 Jul 21 09:19 part-00000-af44ab2c-c3e8-4e15-b63d-6ed105633941.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/isomasaki/pyspark_batch/dataset/parquet/kenmei=香川県"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|         male_avg| jinko_female_avg|\n",
      "+-----------------+-----------------+\n",
      "|485871.8333333333|523763.6666666667|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#香川県のみのデータ\n",
    "parquet_df = spark.read.parquet(\"/Users/isomasaki/pyspark_batch/dataset/parquet/kenmei=香川県\")\n",
    "parquet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS default.jinko_avg (male_avg double,jinko_female_avg double)\n",
    "    PARTITIONED BY (kenmei String)\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '/Users/isomasaki/pyspark_batch/dataset/parquet/';\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|jinko_avg|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/21 09:19:40 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "22/07/21 09:19:40 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "22/07/21 09:19:40 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/07/21 09:19:40 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "+--------------------+--------------------+------------+\n",
      "|            male_avg|    jinko_female_avg|      kenmei|\n",
      "+--------------------+--------------------+------------+\n",
      "|            893167.5|   944959.6666666666|      三重県|\n",
      "|  1268325.3333333333|  1360099.3333333333|      京都府|\n",
      "|4.0840519833333336E7|4.2415789666666664E7|人口集中地区|\n",
      "|         6.1816723E7|6.4687834833333336E7|        全国|\n",
      "|           2650310.5|           2861527.0|      兵庫県|\n",
      "|  2665781.3333333335|  2923371.8333333335|      北海道|\n",
      "|           2987847.0|           2974638.5|      千葉県|\n",
      "|            490624.0|   547112.3333333334|    和歌山県|\n",
      "|  3492880.3333333335|  3443447.8333333335|      埼玉県|\n",
      "|   571530.6666666666|   638773.6666666666|      大分県|\n",
      "|   4292675.833333333|           4517115.0|      大阪府|\n",
      "|   671178.6666666666|   734736.6666666666|      奈良県|\n",
      "|           1139561.5|           1191255.0|      宮城県|\n",
      "|            542386.5|            608793.0|      宮崎県|\n",
      "|            532857.0|   573049.8333333334|      富山県|\n",
      "|   709497.8333333334|            791301.5|      山口県|\n",
      "|            583603.5|   627811.6666666666|      山形県|\n",
      "|   425777.8333333333|   441831.1666666667|      山梨県|\n",
      "|  1009389.1666666666|  1073025.1666666667|      岐阜県|\n",
      "|   659592.6666666666|   714973.1666666666|      岩手県|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"select * from default.jinko_avg\")\n",
    "df_result.show()\n",
    "#partitionつきのテーブルでは、最初はテーブルの中身を確認できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#メタデータにパーティションを登録\n",
    "spark.sql(\"msck repair table jinko_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|            male_avg|    jinko_female_avg|      kenmei|\n",
      "+--------------------+--------------------+------------+\n",
      "|            893167.5|   944959.6666666666|      三重県|\n",
      "|  1268325.3333333333|  1360099.3333333333|      京都府|\n",
      "|4.0840519833333336E7|4.2415789666666664E7|人口集中地区|\n",
      "|         6.1816723E7|6.4687834833333336E7|        全国|\n",
      "|           2650310.5|           2861527.0|      兵庫県|\n",
      "|  2665781.3333333335|  2923371.8333333335|      北海道|\n",
      "|           2987847.0|           2974638.5|      千葉県|\n",
      "|            490624.0|   547112.3333333334|    和歌山県|\n",
      "|  3492880.3333333335|  3443447.8333333335|      埼玉県|\n",
      "|   571530.6666666666|   638773.6666666666|      大分県|\n",
      "|   4292675.833333333|           4517115.0|      大阪府|\n",
      "|   671178.6666666666|   734736.6666666666|      奈良県|\n",
      "|           1139561.5|           1191255.0|      宮城県|\n",
      "|            542386.5|            608793.0|      宮崎県|\n",
      "|            532857.0|   573049.8333333334|      富山県|\n",
      "|   709497.8333333334|            791301.5|      山口県|\n",
      "|            583603.5|   627811.6666666666|      山形県|\n",
      "|   425777.8333333333|   441831.1666666667|      山梨県|\n",
      "|  1009389.1666666666|  1073025.1666666667|      岐阜県|\n",
      "|   659592.6666666666|   714973.1666666666|      岩手県|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"select * from default.jinko_avg\")\n",
    "df_result.show()\n",
    "#partitionつきのテーブルでは、最初はテーブルの中身を確認できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/21 09:19:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chaper2\")\\\n",
    "    .config(\"hive.exec.dynamic.partition\",\"true\")\\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\",\"nonstrict\")\\\n",
    "    .config(\"spark.sql.session.timeZone\",\"JST\")\\\n",
    "    .config(\"spark.ui.enabled\",\"true\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#仮想テーブルの作成\n",
    "df.createOrReplaceTempView(\"jinko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "|          code|    kenmei|gengo|    wareki|   seireki| chu|       sokei|jinko_male|jinko_female|\n",
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "|都道府県コード|都道府県名| 元号|和暦（年）|西暦（年）|  注|人口（総数）|人口（男）|  人口（女）|\n",
      "|            00|      全国| 大正|         9|      1920|null|    55963053|  28044185|    27918868|\n",
      "|            01|    北海道| 大正|         9|      1920|null|     2359183|   1244322|     1114861|\n",
      "|            02|    青森県| 大正|         9|      1920|null|      756454|    381293|      375161|\n",
      "|            03|    岩手県| 大正|         9|      1920|null|      845540|    421069|      424471|\n",
      "|            04|    宮城県| 大正|         9|      1920|null|      961768|    485309|      476459|\n",
      "|            05|    秋田県| 大正|         9|      1920|null|      898537|    453682|      444855|\n",
      "|            06|    山形県| 大正|         9|      1920|null|      968925|    478328|      490597|\n",
      "|            07|    福島県| 大正|         9|      1920|null|     1362750|    673525|      689225|\n",
      "|            08|    茨城県| 大正|         9|      1920|null|     1350400|    662128|      688272|\n",
      "|            09|    栃木県| 大正|         9|      1920|null|     1046479|    514255|      532224|\n",
      "|            10|    群馬県| 大正|         9|      1920|null|     1052610|    514106|      538504|\n",
      "|            11|    埼玉県| 大正|         9|      1920|null|     1319533|    641161|      678372|\n",
      "|            12|    千葉県| 大正|         9|      1920|null|     1336155|    656968|      679187|\n",
      "|            13|    東京都| 大正|         9|      1920|null|     3699428|   1952989|     1746439|\n",
      "|            14|  神奈川県| 大正|         9|      1920|null|     1323390|    689751|      633639|\n",
      "|            15|    新潟県| 大正|         9|      1920|null|     1776474|    871532|      904942|\n",
      "|            16|    富山県| 大正|         9|      1920|null|      724276|    354775|      369501|\n",
      "|            17|    石川県| 大正|         9|      1920|null|      747360|    364375|      382985|\n",
      "|            18|    福井県| 大正|         9|      1920|null|      599155|    293181|      305974|\n",
      "+--------------+----------+-----+----------+----------+----+------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sparkSQLの実行\n",
    "\n",
    "spark.sql(\"select * from jinko\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------------+\n",
      "|  kenmei|         male_avg|       female_avg|\n",
      "+--------+-----------------+-----------------+\n",
      "|  鳥取県|287885.3333333333|314291.3333333333|\n",
      "|  島根県|         356034.5|388621.6666666667|\n",
      "|  高知県|372268.1666666667|         418517.0|\n",
      "|  徳島県|383399.1666666667|         423152.0|\n",
      "|  福井県|         395512.5|420182.6666666667|\n",
      "|  佐賀県|         408192.5|         456442.5|\n",
      "|  山梨県|425777.8333333333|441831.1666666667|\n",
      "|  香川県|485871.8333333333|523763.6666666667|\n",
      "|和歌山県|         490624.0|547112.3333333334|\n",
      "|  富山県|         532857.0|573049.8333333334|\n",
      "|  宮崎県|         542386.5|         608793.0|\n",
      "|  秋田県|542928.3333333334|         604578.5|\n",
      "|  石川県|         566064.0|         604518.5|\n",
      "|  大分県|571530.6666666666|638773.6666666666|\n",
      "|  山形県|         583603.5|627811.6666666666|\n",
      "|  沖縄県|         654622.0|679050.6666666666|\n",
      "|  岩手県|659592.6666666666|714973.1666666666|\n",
      "|  滋賀県|         662391.0|         680326.0|\n",
      "|  奈良県|671178.6666666666|734736.6666666666|\n",
      "|  青森県|675238.6666666666|751182.1666666666|\n",
      "+--------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_after_t_by_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    select \n",
    "      kenmei,\n",
    "      avg(jinko_male) as male_avg,\n",
    "      avg(jinko_female) as female_avg\n",
    "    from \n",
    "      jinko\n",
    "    where\n",
    "      gengo = \"平成\"\n",
    "      and kenmei != \"人口集中地区以外の地区\"\n",
    "    group by kenmei\n",
    "    order by male_avg\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "df_after_t_by_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "   insert overwrite table jinko_avg partition(kenmei)\n",
    "   select \n",
    "      avg(jinko_male) as male_avg,\n",
    "      avg(jinko_female),kenmei as female_avg\n",
    "    from \n",
    "      jinko\n",
    "    where\n",
    "      gengo = \"平成\"\n",
    "      and kenmei != \"人口集中地区以外の地区\"\n",
    "    group by kenmei\n",
    "    order by male_avg\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|            male_avg|    jinko_female_avg|      kenmei|\n",
      "+--------------------+--------------------+------------+\n",
      "|            893167.5|   944959.6666666666|      三重県|\n",
      "|  1268325.3333333333|  1360099.3333333333|      京都府|\n",
      "|4.0840519833333336E7|4.2415789666666664E7|人口集中地区|\n",
      "|         6.1816723E7|6.4687834833333336E7|        全国|\n",
      "|           2650310.5|           2861527.0|      兵庫県|\n",
      "|  2665781.3333333335|  2923371.8333333335|      北海道|\n",
      "|           2987847.0|           2974638.5|      千葉県|\n",
      "|            490624.0|   547112.3333333334|    和歌山県|\n",
      "|  3492880.3333333335|  3443447.8333333335|      埼玉県|\n",
      "|   571530.6666666666|   638773.6666666666|      大分県|\n",
      "|   4292675.833333333|           4517115.0|      大阪府|\n",
      "|   671178.6666666666|   734736.6666666666|      奈良県|\n",
      "|           1139561.5|           1191255.0|      宮城県|\n",
      "|            542386.5|            608793.0|      宮崎県|\n",
      "|            532857.0|   573049.8333333334|      富山県|\n",
      "|   709497.8333333334|            791301.5|      山口県|\n",
      "|            583603.5|   627811.6666666666|      山形県|\n",
      "|   425777.8333333333|   441831.1666666667|      山梨県|\n",
      "|  1009389.1666666666|  1073025.1666666667|      岐阜県|\n",
      "|   659592.6666666666|   714973.1666666666|      岩手県|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from jinko_avg\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#hint文でスモールファイル問題の解決 /** repartition(1) */ 忘れずに\n",
    "#df2 でキャッシュ\n",
    "df2 = spark.sql(\n",
    "   \"\"\"\n",
    "   insert overwrite table jinko_avg partition(kenmei)\n",
    "   select /** repartition(1) */\n",
    "      avg(jinko_male) as male_avg,\n",
    "      avg(jinko_female),kenmei as female_avg\n",
    "    from \n",
    "      jinko\n",
    "    where\n",
    "      gengo = \"平成\"\n",
    "      and kenmei != \"人口集中地区以外の地区\"\n",
    "    group by kenmei\n",
    "    order by male_avg\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|            male_avg|    jinko_female_avg|      kenmei|\n",
      "+--------------------+--------------------+------------+\n",
      "|            893167.5|   944959.6666666666|      三重県|\n",
      "|  1268325.3333333333|  1360099.3333333333|      京都府|\n",
      "|4.0840519833333336E7|4.2415789666666664E7|人口集中地区|\n",
      "|         6.1816723E7|6.4687834833333336E7|        全国|\n",
      "|           2650310.5|           2861527.0|      兵庫県|\n",
      "|  2665781.3333333335|  2923371.8333333335|      北海道|\n",
      "|           2987847.0|           2974638.5|      千葉県|\n",
      "|            490624.0|   547112.3333333334|    和歌山県|\n",
      "|  3492880.3333333335|  3443447.8333333335|      埼玉県|\n",
      "|   571530.6666666666|   638773.6666666666|      大分県|\n",
      "|   4292675.833333333|           4517115.0|      大阪府|\n",
      "|   671178.6666666666|   734736.6666666666|      奈良県|\n",
      "|           1139561.5|           1191255.0|      宮城県|\n",
      "|            542386.5|            608793.0|      宮崎県|\n",
      "|            532857.0|   573049.8333333334|      富山県|\n",
      "|   709497.8333333334|            791301.5|      山口県|\n",
      "|            583603.5|   627811.6666666666|      山形県|\n",
      "|   425777.8333333333|   441831.1666666667|      山梨県|\n",
      "|  1009389.1666666666|  1073025.1666666667|      岐阜県|\n",
      "|   659592.6666666666|   714973.1666666666|      岩手県|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#本番環境を想定したpyspark 昭和\n",
    "spark.sql(\"select * from jinko_avg\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localhost:4040から"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/21 09:36:12 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.cache()\n",
    "df2.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#テーブルをキャッシュ\n",
    "spark.catalog.cacheTable(\"jinko_avg\")\n",
    "spark.catalog.isCached(\"jinko_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "|都道府県コード|都道府県名|元号|和暦（年）|西暦（年）|  注|人口（総数）|人口（男）|人口（女）|\n",
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "|            00|      全国|大正|         9|      1920|null|    55963053|  28044185|  27918868|\n",
      "|            01|    北海道|大正|         9|      1920|null|     2359183|   1244322|   1114861|\n",
      "|            02|    青森県|大正|         9|      1920|null|      756454|    381293|    375161|\n",
      "|            03|    岩手県|大正|         9|      1920|null|      845540|    421069|    424471|\n",
      "|            04|    宮城県|大正|         9|      1920|null|      961768|    485309|    476459|\n",
      "|            05|    秋田県|大正|         9|      1920|null|      898537|    453682|    444855|\n",
      "|            06|    山形県|大正|         9|      1920|null|      968925|    478328|    490597|\n",
      "|            07|    福島県|大正|         9|      1920|null|     1362750|    673525|    689225|\n",
      "|            08|    茨城県|大正|         9|      1920|null|     1350400|    662128|    688272|\n",
      "|            09|    栃木県|大正|         9|      1920|null|     1046479|    514255|    532224|\n",
      "|            10|    群馬県|大正|         9|      1920|null|     1052610|    514106|    538504|\n",
      "|            11|    埼玉県|大正|         9|      1920|null|     1319533|    641161|    678372|\n",
      "|            12|    千葉県|大正|         9|      1920|null|     1336155|    656968|    679187|\n",
      "|            13|    東京都|大正|         9|      1920|null|     3699428|   1952989|   1746439|\n",
      "|            14|  神奈川県|大正|         9|      1920|null|     1323390|    689751|    633639|\n",
      "|            15|    新潟県|大正|         9|      1920|null|     1776474|    871532|    904942|\n",
      "|            16|    富山県|大正|         9|      1920|null|      724276|    354775|    369501|\n",
      "|            17|    石川県|大正|         9|      1920|null|      747360|    364375|    382985|\n",
      "|            18|    福井県|大正|         9|      1920|null|      599155|    293181|    305974|\n",
      "|            19|    山梨県|大正|         9|      1920|null|      583453|    290817|    292636|\n",
      "+--------------+----------+----+----------+----------+----+------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#メタデータについて mysqlにmetadatastoreを作成\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "|code|                kenmei|gengo|wareki|seireki| chu|    sokei|jinko_male|jinko_female|\n",
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "|  00|                  全国| 平成|     2|   1990|null|123611167|  60696724|    62914443|\n",
      "|  0A|          人口集中地区| 平成|     2|   1990|null| 78152452|  38564229|    39588223|\n",
      "|  0B|人口集中地区以外の地区| 平成|     2|   1990|null| 45458715|  22132495|    23326220|\n",
      "|  01|                北海道| 平成|     2|   1990|null|  5643647|   2722988|     2920659|\n",
      "|  02|                青森県| 平成|     2|   1990|null|  1482873|    704758|      778115|\n",
      "|  03|                岩手県| 平成|     2|   1990|null|  1416928|    680197|      736731|\n",
      "|  04|                宮城県| 平成|     2|   1990|null|  2248558|   1105103|     1143455|\n",
      "|  05|                秋田県| 平成|     2|   1990|null|  1227478|    584678|      642800|\n",
      "|  06|                山形県| 平成|     2|   1990|null|  1258390|    607041|      651349|\n",
      "|  07|                福島県| 平成|     2|   1990|null|  2104058|   1024354|     1079704|\n",
      "|  08|                茨城県| 平成|     2|   1990|null|  2845382|   1419117|     1426265|\n",
      "|  09|                栃木県| 平成|     2|   1990|null|  1935168|    962571|      972597|\n",
      "|  10|                群馬県| 平成|     2|   1990|null|  1966265|    971704|      994561|\n",
      "|  11|                埼玉県| 平成|     2|   1990|null|  6405319|   3245868|     3159451|\n",
      "|  12|                千葉県| 平成|     2|   1990|null|  5555429|   2802774|     2752655|\n",
      "|  13|                東京都| 平成|     2|   1990|null| 11855563|   5969773|     5885790|\n",
      "|  14|              神奈川県| 平成|     2|   1990|null|  7980391|   4098147|     3882244|\n",
      "|  15|                新潟県| 平成|     2|   1990|null|  2474583|   1200376|     1274207|\n",
      "|  16|                富山県| 平成|     2|   1990|null|  1120161|    538640|      581521|\n",
      "|  17|                石川県| 平成|     2|   1990|null|  1164628|    562684|      601944|\n",
      "+----+----------------------+-----+------+-------+----+---------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#日本語のカラム名をローマ字へ変換\n",
    "from pyspark.sql.types import StructType,StructField,StringType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "struct = StructType([\n",
    "    StructField(\"code\",StringType(),False),\n",
    "    StructField(\"kenmei\",StringType(),False),\n",
    "    StructField(\"gengo\",StringType(),False),\n",
    "    StructField(\"wareki\",StringType(),False),\n",
    "    StructField(\"seireki\",StringType(),False),\n",
    "    StructField(\"chu\",StringType(),False),\n",
    "    StructField(\"sokei\",StringType(),False),\n",
    "    StructField(\"jinko_male\",StringType(),False),\n",
    "    StructField(\"jinko_female\",StringType(),False)\n",
    "])\n",
    "\n",
    "df = spark.read.option(\"multiLine\",\"true\").option(\"encoding\",\"SJIS\") \\\n",
    ".csv(\"/Users/isomasaki/pyspark_batch/dataset/jinko.csv\",header=False,sep=\",\",inferSchema=False,schema=struct)\n",
    "\n",
    "data_t = df.filter(\"code!='都道府県コード'\").filter(\"gengo='平成'\")\n",
    "data_t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 09:19:58 WARN ObjectStore: Failed to get database data_management_c, returning NoSuchObjectException\n",
      "22/07/22 09:19:58 WARN ObjectStore: Failed to get database data_management_c, returning NoSuchObjectException\n",
      "22/07/22 09:19:58 WARN ObjectStore: Failed to get database data_management_c, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    create database if not exists data_management_c\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 09:46:19 ERROR ConnectionHandle: Database access problem. Killing off this connection and all remaining connections in the connection pool. SQL State = 08S01\n",
      "22/07/22 09:46:19 WARN ObjectStore: Falling back to ORM path due to direct SQL failure (this is not an error): Communications link failure\n",
      "\n",
      "The last packet successfully received from the server was 1,581,243 milliseconds ago. The last packet sent successfully to the server was 1,581,243 milliseconds ago. at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543) at org.datanucleus.api.jdo.JDOPersistenceManager.getDataStoreConnection(JDOPersistenceManager.java:2284) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.executeNoResult(MetaStoreDirectSql.java:252) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.prepareTxn(MetaStoreDirectSql.java:1783) at org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.run(ObjectStore.java:2964) at org.apache.hadoop.hive.metastore.ObjectStore.getDatabaseInternal(ObjectStore.java:740) at org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:714) at jdk.internal.reflect.GeneratedMethodAccessor93.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101) at com.sun.proxy.$Proxy35.getDatabase(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database_core(HiveMetaStore.java:989) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:963) at jdk.internal.reflect.GeneratedMethodAccessor97.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107) at com.sun.proxy.$Proxy36.get_database(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:1288) at jdk.internal.reflect.GeneratedMethodAccessor96.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173) at com.sun.proxy.$Proxy37.getDatabase(Unknown Source) at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563) at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552) at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609) at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:394) at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:294) at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:225) at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:224) at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:274) at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:394) at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:223) at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23) at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:101) at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:223) at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.databaseExists(ExternalCatalogWithListener.scala:69) at org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:290) at org.apache.spark.sql.catalyst.catalog.SessionCatalog.requireDbExists(SessionCatalog.scala:218) at org.apache.spark.sql.catalyst.catalog.SessionCatalog.createTable(SessionCatalog.scala:364) at org.apache.spark.sql.execution.command.CreateTableCommand.run(tables.scala:169) at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75) at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73) at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84) at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109) at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779) at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64) at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94) at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584) at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176) at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584) at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30) at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30) at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30) at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560) at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94) at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81) at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79) at org.apache.spark.sql.Dataset.<init>(Dataset.scala:220) at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779) at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779) at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617) at jdk.internal.reflect.GeneratedMethodAccessor125.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357) at py4j.Gateway.invoke(Gateway.java:282) at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) at py4j.commands.CallCommand.execute(CallCommand.java:79) at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) at py4j.ClientServerConnection.run(ClientServerConnection.java:106) at java.base/java.lang.Thread.run(Thread.java:834);\n",
      " Caused by: Communications link failure\n",
      "\n",
      "The last packet successfully received from the server was 1,581,243 milliseconds ago. The last packet sent successfully to the server was 1,581,243 milliseconds ago. at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64) at com.mysql.cj.jdbc.ConnectionImpl.isReadOnly(ConnectionImpl.java:1402) at com.mysql.cj.jdbc.ConnectionImpl.isReadOnly(ConnectionImpl.java:1387) at com.jolbox.bonecp.ConnectionHandle.isReadOnly(ConnectionHandle.java:867) at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:406) at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getXAResource(ConnectionFactoryImpl.java:361) at org.datanucleus.store.connection.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:316) at org.datanucleus.store.connection.AbstractConnectionFactory.getConnection(AbstractConnectionFactory.java:84) at org.datanucleus.store.rdbms.RDBMSStoreManager.getNucleusConnection(RDBMSStoreManager.java:1351) at org.datanucleus.api.jdo.JDOPersistenceManager.getDataStoreConnection(JDOPersistenceManager.java:2272);\n",
      " Caused by: Communications link failure\n",
      "\n",
      "The last packet successfully received from the server was 1,581,243 milliseconds ago. The last packet sent successfully to the server was 1,581,243 milliseconds ago. at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:61) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:105) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:151) at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:167) at com.mysql.cj.protocol.a.NativeProtocol.send(NativeProtocol.java:628) at com.mysql.cj.protocol.a.NativeProtocol.sendCommand(NativeProtocol.java:683) at com.mysql.cj.protocol.a.NativeProtocol.sendCommand(NativeProtocol.java:155) at com.mysql.cj.NativeSession.queryServerVariable(NativeSession.java:597) at com.mysql.cj.jdbc.ConnectionImpl.isReadOnly(ConnectionImpl.java:1394);\n",
      " Caused by: Broken pipe (Write failed) at java.base/java.net.SocketOutputStream.socketWrite0(Native Method) at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110) at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150) at java.base/sun.security.ssl.SSLSocketOutputRecord.deliver(SSLSocketOutputRecord.java:346) at java.base/sun.security.ssl.SSLSocketImpl$AppOutputStream.write(SSLSocketImpl.java:1208) at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81) at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142) at com.mysql.cj.protocol.a.SimplePacketSender.send(SimplePacketSender.java:55) at com.mysql.cj.protocol.a.TimeTrackingPacketSender.send(TimeTrackingPacketSender.java:50) at com.mysql.cj.protocol.a.NativeProtocol.send(NativeProtocol.java:619)\n",
      "22/07/22 09:46:20 ERROR ConnectionHandle: Database access problem. Killing off this connection and all remaining connections in the connection pool. SQL State = 08S01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    create table if not exists data_management_c.jinko_t (\n",
    "        code String,\n",
    "        gengo String,\n",
    "        wareki String,\n",
    "        seireki String,\n",
    "        chu String,\n",
    "        sokei String,\n",
    "        jinko_male String,\n",
    "        jinko_female String\n",
    "    )\n",
    "    PARTITIONED BY (kenmei String)\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '/Users/isomasaki/pyspark_datamanagement_metadata/dataset/data_management_c.db/jinko_t';\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    create table if not exists data_management_c.jinko_code (code String , kenmei String)\n",
    "    row format delimited\n",
    "    fields terminated by ','\n",
    "    lines terminated by '\\n'\n",
    "    LOCATION '/Users/isomasaki/pyspark_datamanagement_metadata/dataset/data_management_c.db/jinko_code';\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-----------+\n",
      "|namespace        |tableName |isTemporary|\n",
      "+-----------------+----------+-----------+\n",
      "|data_management_c|jinko_code|false      |\n",
      "|data_management_c|jinko_t   |false      |\n",
      "|                 |jinko     |true       |\n",
      "+-----------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in data_management_c\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|createtab_stmt                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CREATE TABLE data_management_c.jinko_t (\\n  code STRING,\\n  gengo STRING,\\n  wareki STRING,\\n  seireki STRING,\\n  chu STRING,\\n  sokei STRING,\\n  jinko_male STRING,\\n  jinko_female STRING,\\n  kenmei STRING)\\nUSING parquet\\nPARTITIONED BY (kenmei)\\nLOCATION 'file:/Users/isomasaki/pyspark_datamanagement_metadata/dataset/data_management_c.db/jinko_t'\\nTBLPROPERTIES (\\n  'transient_lastDdlTime' = '1658450780')\\n|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#テーブル定義\n",
    "spark.sql(\"show create table data_management_c.jinko_t\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2357\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2344\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2378\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2348\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2349\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2334\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2334\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2343\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2356\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2350\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2353\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2340\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2342\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2348\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2339\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2376\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2360\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2336\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2334\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2342\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2352\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2373\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2356\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2338\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2341\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2407\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2361\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2362\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2341\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2358\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2362\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2347\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2347\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2375\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2349\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2341\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2341\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2353\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2343\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2356\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2350\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2358\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2396\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2405\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2330\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2336\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2342\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2375\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2347\n",
      "22/07/23 14:11:02 WARN log: Updating partition stats fast for: jinko_t\n",
      "22/07/23 14:11:02 WARN log: Updated size to 2336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfからテーブルにデータを登録\n",
    "data_t.createOrReplaceTempView(\"jinko_table_tmp\") \n",
    "#tmpテーブルからテーブルへ移動\n",
    "spark.sql(\"\"\" \n",
    "          insert overwrite table data_management_c.jinko_t partition(kenmei)\n",
    "          /** repartition(1) */\n",
    "          select \n",
    "            code,\n",
    "            gengo,\n",
    "            wareki,\n",
    "            seireki,\n",
    "            chu,\n",
    "            sokei,\n",
    "            jinko_male,\n",
    "            jinko_female,\n",
    "            kenmei\n",
    "          from \n",
    "            jinko_table_tmp\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---+\n",
      "|                kenmei|cnt|\n",
      "+----------------------+---+\n",
      "|人口集中地区以外の地区|  6|\n",
      "|              神奈川県|  6|\n",
      "|          人口集中地区|  6|\n",
      "|                  全国|  6|\n",
      "|                愛知県|  6|\n",
      "|                東京都|  6|\n",
      "|                千葉県|  6|\n",
      "|                埼玉県|  6|\n",
      "|                長野県|  6|\n",
      "|                大阪府|  6|\n",
      "|                静岡県|  6|\n",
      "|                宮城県|  6|\n",
      "|                北海道|  6|\n",
      "|                福岡県|  6|\n",
      "|                栃木県|  6|\n",
      "|                京都府|  6|\n",
      "|                秋田県|  6|\n",
      "|                新潟県|  6|\n",
      "|                兵庫県|  6|\n",
      "|                茨城県|  6|\n",
      "+----------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select\n",
    "            kenmei,\n",
    "            count(1) as cnt\n",
    "          from \n",
    "            data_management_c.jinko_t\n",
    "          group by kenmei\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#codeにデータを登録\n",
    "\n",
    "data_t.createOrReplaceTempView(\"jinko_code_tmp\")\n",
    "spark.sql(\"\"\"\n",
    "          insert overwrite table data_management_c.jinko_code\n",
    "          /** repartition(1) */\n",
    "          select\n",
    "            case kenmei\n",
    "              when \"人口集中地区\" then \"elsecode\"\n",
    "              when \"全国\" then \"allct\"\n",
    "              when \"神奈川県\" then \"AA\"\n",
    "            else code \n",
    "            end as code,\n",
    "            kenmei\n",
    "          from \n",
    "            jinko_code_tmp\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+\n",
      "|    code|                kenmei|\n",
      "+--------+----------------------+\n",
      "|   allct|                  全国|\n",
      "|elsecode|          人口集中地区|\n",
      "|      0B|人口集中地区以外の地区|\n",
      "|      01|                北海道|\n",
      "|      02|                青森県|\n",
      "|      03|                岩手県|\n",
      "|      04|                宮城県|\n",
      "|      05|                秋田県|\n",
      "|      06|                山形県|\n",
      "|      07|                福島県|\n",
      "|      08|                茨城県|\n",
      "|      09|                栃木県|\n",
      "|      10|                群馬県|\n",
      "|      11|                埼玉県|\n",
      "|      12|                千葉県|\n",
      "|      13|                東京都|\n",
      "|      AA|              神奈川県|\n",
      "|      15|                新潟県|\n",
      "|      16|                富山県|\n",
      "|      17|                石川県|\n",
      "+--------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select\n",
    "            *\n",
    "          from \n",
    "            data_management_c.jinko_code\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ビジネスメタデータ(カラム名確認)\n",
    "#select co.COLUMN_NAME from TBLS as t inner join SDS as s on t.SD = s.SD_ID inner join CDS as c on s.CD=c.CD_ID inner join COLUMNS_V2 as co on c.CD_ID = co.CD_ID where TBL_NAME = \"jinko_t\";\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "--メタデータを保存するためのデータベースとテーブル\n",
    "create database if not exists metadata;\n",
    "use metadata;\n",
    "create table if not exists metadatas (\n",
    "    database_name varchar(255),\n",
    "    table_name varchar(255),\n",
    "    table_definition varchar(255),\n",
    "    sammary varchar(255),\n",
    "    row_num varchar(255),\n",
    "    selectivity varchar(255),\n",
    "    consistency_flag varchar(255),\n",
    "    frequency_flag varchar(255),\n",
    "    primary key (database_name,table_name)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/opt/homebrew/opt/apache-spark/libexec/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark sessionの作成\n",
    "# spark.ui.enabled trueとするとSparkのGUI画面を確認することができます\n",
    "# spark.eventLog.enabled true　とすると　GUIで実行ログを確認することができます\n",
    "# GUIなどの確認は最後のセクションで説明を行います。\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chapter2\") \\\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\") \\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"JST\") \\\n",
    "    .config(\"spark.ui.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          create database if not exists metadata_tmp\n",
    "          \"\"\")\n",
    "spark.sql(\"\"\"\n",
    "           create table if not exists metadata_tmp.sample_metadata(\n",
    "    database_name String,\n",
    "    table_name String,\n",
    "    table_definition String,\n",
    "    sammary String)\n",
    "STORED AS PARQUET\n",
    "LOCATION \"/Users/isomasaki/pyspark_datamanagement_metadata/dataset/metadata_tmp.db/sample_metadata\";\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "create table if not exists metadata_tmp.sample_metadata(\n",
    "    database_name String,\n",
    "    table_name String,\n",
    "    table_definition String,\n",
    "    sammary String,\n",
    "    row_num String,\n",
    "    selectivity String,\n",
    "    consistency_flag String,\n",
    "    frequency_flag String)\n",
    "STORED AS PARQUET\n",
    "LOCATION \"/Users/isomasaki/pyspark_datamanagement_metadata/dataset/metadata_tmp.db/sample_metadata\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-----------+\n",
      "|   namespace|      tableName|isTemporary|\n",
      "+------------+---------------+-----------+\n",
      "|metadata_tmp|sample_metadata|      false|\n",
      "|            |     sample_tmp|       true|\n",
      "+------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in metadata_tmp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,BooleanType\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "#spark経由でテーブル定義を取得\n",
    "table_def = spark.sql(\"\"\"\n",
    "                      show create table data_management_c.jinko_t\n",
    "                      \"\"\").collect()[0].asDict()[\"createtab_stmt\"]\n",
    "\n",
    "struct = StructType([StructField(\"database_name\",StringType(),True),\n",
    "                     StructField(\"table_name\",StringType(),True),\n",
    "                     StructField(\"table_definition\",StringType(),True),\n",
    "                     StructField(\"sammary\",StringType(),True),\n",
    "                     StructField(\"row_num\",StringType(),True),\n",
    "                     StructField(\"selectivity\",StringType(),True),\n",
    "                     StructField(\"consistency_flag\",StringType(),True),\n",
    "                     StructField(\"frequency_flag\",StringType(),True)\n",
    "                     ])\n",
    "df_meta = spark.createDataFrame([(None,None,None,None,None,None,None,None)],struct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+-----------+----------------+--------------+\n",
      "|database_name    |table_name|table_definition                                                                                                                                                                                                                                                                                                                                                                                                           |sammary     |row_num|selectivity|consistency_flag|frequency_flag|\n",
      "+-----------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+-----------+----------------+--------------+\n",
      "|data_management_c|jinko_t   |CREATE TABLE data_management_c.jinko_t (\\n  code STRING,\\n  gengo STRING,\\n  wareki STRING,\\n  seireki STRING,\\n  chu STRING,\\n  sokei STRING,\\n  jinko_male STRING,\\n  jinko_female STRING,\\n  kenmei STRING)\\nUSING parquet\\nPARTITIONED BY (kenmei)\\nLOCATION 'file:/Users/isomasaki/pyspark_datamanagement_metadata/dataset/data_management_c.db/jinko_t'\\nTBLPROPERTIES (\\n  'transient_lastDdlTime' = '1658450780')\\n|一旦説明は空|null   |null       |null            |null          |\n",
      "+-----------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------+-----------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_meta2 = df_meta.withColumn(\"database_name\",when(df_meta.database_name.isNull(),\"data_management_c\").otherwise(df_meta.database_name))\n",
    "df_meta2 = df_meta2.withColumn(\"table_name\",when(df_meta.table_name.isNull(),\"jinko_t\").otherwise(df_meta.table_name))\n",
    "df_meta2 = df_meta2.withColumn(\"table_definition\",when(df_meta.table_definition.isNull(),table_def).otherwise(df_meta.table_definition))\n",
    "df_meta2 = df_meta2.withColumn(\"sammary\",when(df_meta.sammary.isNull(),\"一旦説明は空\").otherwise(df_meta.sammary))\n",
    "\n",
    "df_meta2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta2.createOrReplaceTempView(\"sample_tmp\")\n",
    "spark.sql(\"\"\"\n",
    "          insert overwrite table metadata_tmp.sample_metadata\n",
    "          select /** repartition(1) */\n",
    "            *\n",
    "          from \n",
    "            sample_tmp\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+------------+-------+-----------+----------------+--------------+\n",
      "|    database_name|table_name|    table_definition|     sammary|row_num|selectivity|consistency_flag|frequency_flag|\n",
      "+-----------------+----------+--------------------+------------+-------+-----------+----------------+--------------+\n",
      "|data_management_c|   jinko_t|CREATE TABLE data...|一旦説明は空|   null|       null|            null|          null|\n",
      "+-----------------+----------+--------------------+------------+-------+-----------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select \n",
    "            *\n",
    "          from \n",
    "            metadata_tmp.sample_metadata\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7d8ad7bcba743a950284a9d2689718111e12ebf705e68eb2847164e6b44765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
